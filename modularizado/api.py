from typing import Optional, Dict

from fastapi import FastAPI, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse, JSONResponse
from pydantic import BaseModel
from dotenv import load_dotenv
import os
import re
import json
import unicodedata
import google.generativeai as genai
from google.cloud import speech
from groq import Groq

from ingesta import processar_arquivos
from rag import buscar_contexto
from verificador_base_fixa import buscar_resposta_fixa
from resposta_ia import stream_resposta
from sessoes import session_store
from config import GROQ_API_KEY, MODELO_IA
from google_maps import gerar_links_orgaos
from contexto_conversa import formatar_historico_conversa


load_dotenv()
genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))
client_groq = Groq(api_key=GROQ_API_KEY)


class Perfil(BaseModel):
    nome: Optional[str] = None
    idade: Optional[int] = None
    genero: Optional[str] = None
    papel: Optional[str] = None
    problema: Optional[str] = None
    localidade: Optional[str] = None
    intent: Optional[str] = None
    eixo: Optional[str] = None        # CPF, RG, BOLSA, PASSAPORTE, GOVBR, IMPOSTO_RENDA, OUTRO
    subtrilha: Optional[str] = None   # bloqueado, emissao, pendente, etc.


class ChatRequest(BaseModel):
    pergunta: str
    session_id: Optional[str] = None
    perfil: Optional[Perfil] = None
    transcricao: Optional[str] = None


class SessionRequest(BaseModel):
    session_id: str
    perfil: Perfil


def tentar_preencher_perfil_livre(texto: str) -> Dict:
    partes = [p.strip() for p in re.split(r"[,\n]", texto) if p.strip()]
    perfil: Dict = {}
    texto_lower = texto.lower()

    if partes:
        # tenta capturar nome se frase for curta tipo "sou Joao" ou "meu nome e ..."
        if "me chamo" in texto_lower or texto_lower.startswith("sou "):
            tokens = texto.split()
            if len(tokens) >= 2:
                perfil["nome"] = tokens[-1]
        if "meu nome" in texto_lower:
            tokens = texto.replace("√©", " ").replace("√â", " ").split()
            for i, t in enumerate(tokens):
                if t.lower() == "nome" and i + 1 < len(tokens):
                    perfil["nome"] = tokens[i + 1]
                    break

        for p in partes:
            m = re.search(r"(\d{1,3})", p)
            if m:
                try:
                    idade = int(m.group(1))
                    if 0 < idade < 130:
                        perfil["idade"] = idade
                        break
                except Exception:
                    pass

        if any(g in texto_lower for g in ["mulher", "feminino"]):
            perfil["genero"] = "mulher"
        elif any(g in texto_lower for g in ["homem", "masculino"]):
            perfil["genero"] = "homem"
        elif "trans" in texto_lower:
            perfil["genero"] = "trans"
        elif "nb" in texto_lower or "nao bin" in texto_lower or "n√£o bin" in texto_lower:
            perfil["genero"] = "nao-binario"

        if "m√£e" in texto_lower or "mae" in texto_lower:
            perfil["papel"] = "mae"
        elif "pai" in texto_lower:
            perfil["papel"] = "pai"
        elif "respons" in texto_lower:
            perfil["papel"] = "responsavel"
        elif "idos" in texto_lower:
            perfil["papel"] = "idoso"

        estados = [
            "acre", "alagoas", "amapa", "amazonas", "bahia", "ceara", "distrito federal", "espirito santo", "goias",
            "maranhao", "mato grosso", "mato grosso do sul", "minas gerais", "para", "paraiba", "parana",
            "pernambuco", "piaui", "rio de janeiro", "rio grande do norte", "rio grande do sul", "rondonia",
            "roraima", "santa catarina", "sao paulo", "sergipe", "tocantins"
        ]
        siglas = ["ac", "al", "ap", "am", "ba", "ce", "df", "es", "go", "ma", "mt", "ms", "mg", "pa", "pb", "pr",
                  "pe", "pi", "rj", "rn", "rs", "ro", "rr", "sc", "sp", "se", "to"]
        
        # Normaliza brasilia/bras√≠lia para distrito federal
        if "brasilia" in texto_lower or "bras√≠lia" in texto_lower:
            perfil["localidade"] = "distrito federal"
        else:
            for estado in estados:
                if estado in texto_lower:
                    perfil["localidade"] = estado
                    break
            if "localidade" not in perfil:
                tokens = [t.strip(",. ").lower() for t in texto.split()]
                for t in tokens:
                    if t in siglas:
                        perfil["localidade"] = t
                        break

        if "problema" not in perfil or not perfil.get("problema"):
            if len(partes) >= 2:
                perfil["problema"] = ", ".join(partes[-2:])
            else:
                perfil["problema"] = texto

    return {k: v for k, v in perfil.items() if v}


DOC_KEYWORDS = [
    "cpf", "rg", "identidade", "cin", "sus", "cartao sus", "cart√£o sus",
    "bolsa", "auxilio", "aux√≠lio", "cadunico", "cad√∫nico", "passaporte",
    "gov", "gov.br", "imposto", "irpf", "ir", "cnpj", "mei", "empresa"
]


def has_assunto_doc(texto: str) -> bool:
    lower = texto.lower()
    return any(chave in lower for chave in DOC_KEYWORDS)


def contexto_relevante(contexto: str, pergunta: str, eixo: Optional[str]) -> bool:
    """
    Confere se o contexto cont√©m termos do assunto principal (palavras-chave da pergunta ou eixo).
    Evita responder com documentos desconexos (ex.: IRPF para pergunta de CNPJ).
    """
    ctx_lower = contexto.lower()
    pergunta_lower = pergunta.lower()

    termos = {kw for kw in DOC_KEYWORDS if kw in pergunta_lower}
    if eixo:
        eixo_l = eixo.lower()
        if eixo_l == "cpf":
            termos.update(["cpf"])
        elif eixo_l == "rg":
            termos.update(["rg", "identidade", "cin"])
        elif eixo_l == "sus":
            termos.update(["sus", "cartao sus", "cart√£o sus", "cartao do sus", "sistema unico de saude"])
        elif eixo_l == "bolsa":
            termos.update(["bolsa", "auxilio", "aux√≠lio", "cadunico", "cad√∫nico"])
        elif eixo_l == "passaporte":
            termos.update(["passaporte"])
        elif eixo_l == "govbr":
            termos.update(["gov", "gov.br"])
        elif eixo_l == "imposto_renda":
            termos.update(["imposto", "irpf", "imposto de renda", "ir"])
        elif eixo_l == "cnpj":
            termos.update(["cnpj", "empresa", "mei", "abertura de empresa"])

    # Se n√£o h√° termo para checar, n√£o bloqueia
    if not termos:
        return True

    return any(t in ctx_lower for t in termos)


def extrair_perfil_llm(texto: str) -> Dict:
    prompt = f"""
    Extraia dados do perfil a partir do texto do cidad√£o.
    Campos: nome (primeiro nome), genero (identidade de g√™nero), papel (m√£e, pai, respons√°vel, idoso), idade (n√∫mero), localidade (estado/UF ou cidade), problema (frase curta do pedido).
    Responda apenas em JSON com chaves: nome, genero, papel, idade, localidade, problema. Use string vazia se n√£o souber.

    Texto: {texto}
    """
    try:
        completion = client_groq.chat.completions.create(
            model=MODELO_IA,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.1,
            top_p=0.1,
        )
        content = completion.choices[0].message.content or "{}"
        data = json.loads(content)
        return {k: v for k, v in data.items() if v}
    except Exception as e:
        print(f"[perfil_llm][erro] {type(e).__name__}: {e}")
        return {}


def detectar_papel_llm(texto: str) -> Optional[str]:
    """
    Usa LLM para detectar se o atendimento √© para o pr√≥prio usu√°rio ou para algu√©m da fam√≠lia.
    Retorna: "titular" (para si mesmo) ou "responsavel" (para algu√©m da fam√≠lia)
    """
    prompt = f"""Analise a resposta do usu√°rio e determine se o atendimento √© para ele mesmo ou para algu√©m da fam√≠lia.

Exemplos de respostas que indicam "para si mesmo" (titular):
- "sou eu", "sou eu mesmo", "√© pra mim", "para mim", "pra mim", "eu mesmo", "para mim mesmo", "√© para mim", "eu", "para eu", "pra eu"

Exemplos de respostas que indicam "para algu√©m da fam√≠lia" (responsavel):
- "filho", "filha", "dependente", "para meu filho", "para minha filha", "para algu√©m da fam√≠lia", "para outro"

Resposta do usu√°rio: "{texto}"

Responda APENAS com uma palavra: "titular" ou "responsavel"
Se n√£o conseguir determinar com certeza, responda "titular".
"""
    try:
        completion = client_groq.chat.completions.create(
            model=MODELO_IA,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.1,
            top_p=0.1,
        )
        content = completion.choices[0].message.content or "titular"
        content = content.strip().lower()
        # Remove poss√≠veis espa√ßos ou pontua√ß√£o
        content = re.sub(r'[^\w]', '', content)
        if "responsavel" in content or "responsvel" in content:
            return "responsavel"
        return "titular"
    except Exception as e:
        print(f"[detectar_papel_llm][erro] {type(e).__name__}: {e}")
        return None


def preencher_resposta_curta(pergunta: str, perfil: Dict) -> Dict:
    texto = pergunta.strip()
    lower = texto.lower()

    if not perfil.get("nome"):
        tokens = texto.split()
        if len(tokens) == 1 and tokens[0].isalpha():
            perfil["nome"] = tokens[0]

    if not perfil.get("papel"):
        # Detec√ß√£o melhorada com mais varia√ß√µes
        indicadores_titular = [
            "pra mim", "para mim", "√© pra mim", "√© para mim", "para mim mesmo", 
            "pra mim mesmo", "sou eu", "sou eu mesmo", "eu mesmo", "eu", 
            "para eu", "pra eu", "para si", "pra si"
        ]
        indicadores_responsavel = [
            "filho", "filha", "dependente", "para meu filho", "para minha filha",
            "para algu√©m", "para alguem", "para outro", "para outra pessoa"
        ]
        
        # Verifica indicadores simples primeiro
        if any(ind in lower for ind in indicadores_responsavel):
            perfil["papel"] = "responsavel"
        elif any(ind in lower for ind in indicadores_titular):
            perfil["papel"] = "titular"
        else:
            # Se n√£o detectou, usa LLM para detectar
            papel_detectado = detectar_papel_llm(texto)
            if papel_detectado:
                perfil["papel"] = papel_detectado

    if not perfil.get("localidade"):
        # Normaliza brasilia/bras√≠lia para distrito federal
        if "brasilia" in lower or "bras√≠lia" in lower:
            perfil["localidade"] = "distrito federal"
        else:
            siglas = ["ac", "al", "ap", "am", "ba", "ce", "df", "es", "go", "ma", "mt", "ms",
                      "mg", "pa", "pb", "pr", "pe", "pi", "rj", "rn", "rs", "ro", "rr", "sc", "sp", "se", "to"]
            tokens = [t.strip(",. ").lower() for t in texto.split()]
            for t in tokens:
                if t in siglas:
                    perfil["localidade"] = t
                    break

    return perfil


def resumo_perfil(perfil: Dict) -> str:
    partes = []
    if perfil.get("nome"):
        partes.append(f"nome={perfil['nome']}")
    if perfil.get("localidade"):
        partes.append(f"estado={perfil['localidade']}")
    if perfil.get("papel"):
        partes.append(f"para={perfil['papel']}")
    if perfil.get("intent"):
        partes.append(f"assunto={perfil['intent']}")
    if perfil.get("problema"):
        partes.append(f"pedido={perfil['problema']}")
    if perfil.get("eixo"):
        partes.append(f"eixo={perfil['eixo']}")
    if perfil.get("subtrilha"):
        partes.append(f"subtrilha={perfil['subtrilha']}")
    return ", ".join(partes) if partes else "ainda n√£o tenho dados suficientes."


def resposta_smalltalk(pergunta: str) -> Optional[str]:
    base = pergunta.strip().lower()
    gatilhos = ["oi", "ol√°", "ola", "bom dia", "boa tarde", "boa noite", "tudo bem", "como vai"]
    if any(base.startswith(g) for g in gatilhos) and not has_assunto_doc(base):
        return "Oi! Posso ajudar com RG, CPF, passaporte ou benef√≠cios como Bolsa Fam√≠lia e SUS. Sobre o que voc√™ quer falar?"
    if "obrigado" in base or "valeu" in base:
        return "De nada! Se precisar de mais alguma coisa sobre documentos ou servi√ßos p√∫blicos, √© s√≥ falar."
    return None


def classificar_eixo(texto: str) -> str:
    t = texto.lower()
    if "cnpj" in t:
        return "CNPJ"
    if "cpf" in t:
        return "CPF"
    if "rg" in t or "identidade" in t or "cin" in t:
        return "RG"
    if "sus" in t or "sistema unico de saude" in t or "sistema √∫nico de sa√∫de" in t or "cartao sus" in t or "cart√£o sus" in t:
        return "SUS"
    if "bolsa" in t or "auxilio" in t or "cadunico" in t:
        return "BOLSA"
    if "passaporte" in t:
        return "PASSAPORTE"
    if "gov" in t or "gov.br" in t:
        return "GOVBR"
    if "imposto" in t or "irpf" in t or "ir" in t:
        return "IMPOSTO_RENDA"
    return "OUTRO"


def classificar_subtrilha(texto: str) -> Optional[str]:
    t = texto.lower()
    if "bloque" in t or "cort" in t or "parou" in t:
        return "bloqueado"
    if "pend" in t or "diverg" in t:
        return "pendencia"
    if "primeira" in t or "primeiro" in t or "emitir" in t or "tirar" in t:
        return "emissao"
    if "renovar" in t or "segunda" in t or "2a via" in t:
        return "segunda_via"
    return None


app = FastAPI(title="Assistente Cidad√£o", version="1.0.0")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Inicializa√ß√£o autom√°tica: processa documentos na inicializa√ß√£o
@app.on_event("startup")
async def inicializar_banco_vetorial():
    """
    Inicializa o banco vetorial processando os documentos na pasta documentos/
    quando o servidor inicia.
    """
    try:
        from banco_dados import colecao_global
        import os
        from config import PASTA_DOCUMENTOS
        
        # Verifica se a pasta de documentos existe
        if not os.path.exists(PASTA_DOCUMENTOS):
            print(f"[startup] ‚ö†Ô∏è Pasta de documentos n√£o encontrada: {PASTA_DOCUMENTOS}")
            os.makedirs(PASTA_DOCUMENTOS, exist_ok=True)
            print(f"[startup] ‚úÖ Pasta criada: {PASTA_DOCUMENTOS}")
        
        # Verifica se a cole√ß√£o j√° tem documentos
        count = colecao_global.count()
        
        # Verifica se existe o arquivo doc-info.txt
        doc_info_path = os.path.join(PASTA_DOCUMENTOS, "doc-info.txt")
        arquivo_existe = os.path.exists(doc_info_path)
        
        print(f"[startup] Verificando banco vetorial...")
        print(f"[startup] - Chunks no banco: {count}")
        print(f"[startup] - Arquivo doc-info.txt existe: {arquivo_existe}")
        print(f"[startup] - Caminho do arquivo: {doc_info_path}")
        
        # FOR√áA ingest√£o sempre que o arquivo existir (garante que doc-info.txt seja processado)
        if arquivo_existe:
            if count == 0:
                print("[startup] üîÑ Banco vetorial vazio. Iniciando ingest√£o autom√°tica...")
            else:
                print(f"[startup] üîÑ Banco possui {count} chunks, mas for√ßando reprocessamento para garantir sincronia...")
            
            # Limpa a cole√ß√£o antes de reprocessar (evita duplicatas)
            try:
                # Deleta todos os documentos existentes
                if count > 0:
                    todos_ids = colecao_global.get()["ids"]
                    if todos_ids:
                        colecao_global.delete(ids=todos_ids)
                        print(f"[startup] üóëÔ∏è Limpou {len(todos_ids)} chunks antigos")
            except Exception as e:
                print(f"[startup] ‚ö†Ô∏è Erro ao limpar cole√ß√£o (pode ignorar): {e}")
            
            # Processa os arquivos
            processar_arquivos()
            count_apos = colecao_global.count()
            if count_apos > 0:
                print(f"[startup] ‚úÖ Ingest√£o conclu√≠da. {count_apos} chunks no banco vetorial.")
            else:
                print(f"[startup] ‚ö†Ô∏è Ingest√£o executada mas nenhum chunk foi criado. Verifique os arquivos.")
        else:
            print(f"[startup] ‚ö†Ô∏è Arquivo doc-info.txt n√£o encontrado em {doc_info_path}")
            print(f"[startup] ‚ö†Ô∏è Banco vetorial n√£o ser√° populado. Verifique se o arquivo est√° no reposit√≥rio.")
    except Exception as e:
        print(f"[startup] ‚ùå Erro ao inicializar banco vetorial: {e}")
        import traceback
        traceback.print_exc()
        # N√£o bloqueia o servidor se der erro na ingest√£o


@app.get("/health")
def health():
    return {"status": "ok"}


@app.post("/ingest")
def ingest():
    processar_arquivos()
    return {"status": "ingestao_disparada"}


@app.post("/session")
def set_session(payload: SessionRequest):
    session_store.upsert(payload.session_id, payload.perfil.model_dump())
    return {"status": "perfil_atualizado"}


@app.post("/transcribe")
async def transcribe(file: UploadFile = File(...)):
    try:
        if not os.getenv("GOOGLE_APPLICATION_CREDENTIALS"):
            return JSONResponse(status_code=500, content={"detail": "GOOGLE_APPLICATION_CREDENTIALS n√£o configurada para Speech-to-Text."})

        audio_bytes = await file.read()
        if not audio_bytes:
            return JSONResponse(status_code=400, content={"detail": "Arquivo de √°udio vazio."})

        mime = (file.content_type or "").lower()
        print(f"[transcribe] mime={mime}, size_bytes={len(audio_bytes)}")

        encoding_map = {
            "audio/webm": speech.RecognitionConfig.AudioEncoding.WEBM_OPUS,
            "audio/ogg": speech.RecognitionConfig.AudioEncoding.OGG_OPUS,
            "audio/opus": speech.RecognitionConfig.AudioEncoding.OGG_OPUS,
            "audio/wav": speech.RecognitionConfig.AudioEncoding.LINEAR16,
            "audio/x-wav": speech.RecognitionConfig.AudioEncoding.LINEAR16,
            "audio/flac": speech.RecognitionConfig.AudioEncoding.FLAC,
            "audio/mpeg": speech.RecognitionConfig.AudioEncoding.MP3,
            "audio/mp3": speech.RecognitionConfig.AudioEncoding.MP3,
        }

        encoding = encoding_map.get(mime)
        if encoding is None:
            return JSONResponse(status_code=400, content={"detail": f"Formato de √°udio n√£o suportado: {mime}. Use webm/ogg opus, wav, flac ou mp3."})

        client_speech = speech.SpeechClient()
        audio = speech.RecognitionAudio(content=audio_bytes)
        sample_rate = 48000 if encoding in (speech.RecognitionConfig.AudioEncoding.WEBM_OPUS, speech.RecognitionConfig.AudioEncoding.OGG_OPUS) else None
        config = speech.RecognitionConfig(
            encoding=encoding,
            language_code="pt-BR",
            enable_automatic_punctuation=True,
            audio_channel_count=1,
            sample_rate_hertz=sample_rate,
        )
        response = client_speech.recognize(config=config, audio=audio)
        textos = [result.alternatives[0].transcript for result in response.results if result.alternatives]
        texto_final = " ".join(textos).strip()

        if not texto_final:
            print(f"[transcribe] resposta vazia do Speech. response={response}")
            return JSONResponse(status_code=500, content={"detail": "Transcri√ß√£o vazia retornada pelo Speech-to-Text."})

        return {"text": texto_final}
    except Exception as e:
        print(f"[transcribe][erro] {type(e).__name__}: {e}")
        return JSONResponse(status_code=500, content={"detail": f"Erro na transcri√ß√£o: {type(e).__name__}: {e}"})


@app.post("/chat")
def chat(payload: ChatRequest):
    pergunta = (payload.transcricao or payload.pergunta).strip()

    if not pergunta:
        return JSONResponse(status_code=400, content={"detail": "Pergunta vazia"})

    perfil_dict: Dict = {}
    hist: list = []
    if payload.session_id:
        armazenado = session_store.get(payload.session_id)
        if armazenado:
            hist = armazenado.get("history", [])
            perfil_dict = {k: v for k, v in armazenado.items() if k != "history"}

    mensagens_recentes = (hist + [pergunta])[-5:]

    def salvar_sessao():
        if payload.session_id:
            dados = dict(perfil_dict)
            dados["history"] = mensagens_recentes
            session_store.upsert(payload.session_id, dados)

    # Fallback seguro para perguntas estranhas sobre nome (se n√£o houver nome salvo)
    if "qual" in pergunta.lower() and "meu nome" in pergunta.lower():
        # nome salvo?
        sess_nome = perfil_dict.get("nome")
        if sess_nome:
            return {"answer": f"Voc√™ me disse que seu nome √© {sess_nome}."}
        return {"answer": "Eu n√£o vejo seu nome automaticamente. Posso ajudar com RG, CPF ou Bolsa Fam√≠lia se voc√™ quiser."}

    resposta_gentil = resposta_smalltalk(pergunta)
    if resposta_gentil:
        salvar_sessao()
        return {"answer": resposta_gentil}

    if pergunta.lower() in ["s√≥ isso", "so isso", "mais nada", "acabou?"]:
        salvar_sessao()
        return {"answer": "Posso detalhar prazos, taxas, documentos ou onde ir no seu estado. O que mais voc√™ precisa?"}

    if payload.perfil:
        perfil_dict.update({k: v for k, v in payload.perfil.model_dump().items() if v})
        salvar_sessao()

    # Classifica eixo/subtrilha quando a mensagem tem assunto claro; evita marcar "OUTRO" em respostas curtas tipo "sim"
    pergunta_lower = pergunta.lower().strip()
    palavras_msg = pergunta_lower.split()
    respostas_curta = {"sim", "ok", "blz", "beleza", "certo", "isso", "ss", "s", "nao", "n√£o"}
    tem_assunto_claro = any(
        chave in pergunta_lower
        for chave in ["cpf", "rg", "sus", "bolsa", "auxilio", "cadunico", "passaporte", "gov", "imposto"]
    ) or len(palavras_msg) >= 3 or (len(palavras_msg) >= 2 and not all(p in respostas_curta for p in palavras_msg))

    trocar_assunto = any(frase in pergunta_lower for frase in ["outro assunto", "agora outro", "mudar de assunto"])
    eixo_detectado = classificar_eixo(pergunta) if tem_assunto_claro else None
    subtrilha_detectada = classificar_subtrilha(pergunta) if tem_assunto_claro else None

    if eixo_detectado and (trocar_assunto or not perfil_dict.get("eixo")):
        perfil_dict["eixo"] = eixo_detectado
    if subtrilha_detectada and not perfil_dict.get("subtrilha"):
        perfil_dict["subtrilha"] = subtrilha_detectada

    if not perfil_dict.get("intent") and tem_assunto_claro:
        perfil_dict["intent"] = pergunta
    salvar_sessao()

    # Tenta preencher perfil com detec√ß√£o autom√°tica
    if not all(perfil_dict.get(campo) for campo in ["nome", "genero", "papel", "idade", "problema", "localidade"]):
        auto = tentar_preencher_perfil_livre(pergunta)
        if auto:
            perfil_dict.update(auto)
            salvar_sessao()

    # Tenta extrair campos com LLM se ainda faltar
    if not all(perfil_dict.get(campo) for campo in ["nome", "genero", "papel", "idade", "problema", "localidade"]):
        llm_extra = extrair_perfil_llm(pergunta)
        if llm_extra:
            for k, v in llm_extra.items():
                if v and not perfil_dict.get(k):
                    perfil_dict[k] = v
            salvar_sessao()

    # Preenche campos simples
    perfil_dict = preencher_resposta_curta(pergunta, perfil_dict)
    salvar_sessao()

    if not perfil_dict.get("problema"):
        perfil_dict["problema"] = pergunta
    if not perfil_dict.get("intent") and tem_assunto_claro:
        perfil_dict["intent"] = pergunta
    salvar_sessao()

    # Perguntas sobre dados do perfil
    lower = pergunta.lower()
    if "meus dados" in lower or "que dados" in lower:
        salvar_sessao()
        return {"answer": f"Voc√™ me contou: {resumo_perfil(perfil_dict)}"}
    if "meu nome" in lower and perfil_dict.get("nome"):
        salvar_sessao()
        return {"answer": f"Voc√™ me disse que seu nome √© {perfil_dict.get('nome')}. Posso seguir na orienta√ß√£o?"}

    # Monta bloco de perfil apenas com campos preenchidos (sem bloquear fluxo se faltar algo)
    partes_perfil = []
    if perfil_dict.get('nome'):
        partes_perfil.append(f"Nome: {perfil_dict.get('nome')}")
    if perfil_dict.get('localidade'):
        partes_perfil.append(f"Localidade: {perfil_dict.get('localidade')}")
    if perfil_dict.get('papel'):
        partes_perfil.append(f"Situa√ß√£o: {perfil_dict.get('papel')}")
    if perfil_dict.get('eixo'):
        partes_perfil.append(f"Assunto: {perfil_dict.get('eixo')}")
    
    bloco_perfil = ""
    if partes_perfil:
        bloco_perfil = "INFORMA√á√ïES DO USU√ÅRIO:\n- " + "\n- ".join(partes_perfil) + "\n\n"

    faltando = []
    if not perfil_dict.get("localidade"):
        faltando.append("Localidade n√£o informada (responder de forma geral).")
    if not perfil_dict.get("papel"):
        faltando.append("Papel n√£o informado (se √© para voc√™ ou dependente).")
    if not perfil_dict.get("nome"):
        faltando.append("Nome n√£o informado.")
    if faltando:
        bloco_perfil += "DADOS FALTANTES PARA PERSONALIZAR MELHOR:\n- " + "\n- ".join(faltando) + "\n\n"

    if mensagens_recentes:
        bloco_perfil += "HIST√ìRICO RECENTE (√∫ltimas 5 mensagens):\n- " + "\n- ".join(mensagens_recentes) + "\n\n"

    resposta_fixa = buscar_resposta_fixa(pergunta)
    if resposta_fixa:
        salvar_sessao()
        return {"answer": resposta_fixa}

    # Monta query de busca melhorada combinando pergunta atual com contexto da conversa
    query_busca = pergunta
    
    # Se a pergunta atual parece ser uma resposta (curta, sem verbo de a√ß√£o), 
    # combina com o intent/eixo anterior ou hist√≥rico recente
    palavras_pergunta = pergunta_lower.split()
    historico_para_busca = " ".join(mensagens_recentes)
    
    # Se a pergunta √© muito curta (1-2 palavras) e h√° um intent/eixo salvo ou hist√≥rico,
    # provavelmente √© uma resposta a uma pergunta anterior
    if len(palavras_pergunta) <= 2 and (perfil_dict.get("intent") or perfil_dict.get("eixo") or historico_para_busca):
        termos_contexto = []
        if perfil_dict.get("eixo"):
            termos_contexto.append(perfil_dict.get("eixo"))
        if perfil_dict.get("intent") and len(perfil_dict.get("intent", "").split()) > 2:
            termos_contexto.append(perfil_dict.get("intent"))
        if historico_para_busca:
            termos_contexto.append(historico_para_busca)
        
        if termos_contexto:
            query_busca = f"{' '.join(termos_contexto)} {pergunta}"
    
    # Adiciona localidade √† busca se dispon√≠vel
    if perfil_dict.get("localidade") and perfil_dict.get("localidade") not in query_busca.lower():
        # Normaliza localidade
        localidade = perfil_dict.get("localidade").lower()
        if localidade == "brasilia" or localidade == "bras√≠lia":
            localidade = "distrito federal"
        query_busca = f"{query_busca} {localidade}"
    
    # Busca contexto com query melhorada
    contexto = buscar_contexto(query_busca, session_id=payload.session_id)
    
    # Se n√£o encontrou, tenta buscar apenas com o eixo/intent
    if (not contexto or contexto.strip() == "") and perfil_dict.get("eixo"):
        contexto = buscar_contexto(perfil_dict.get("eixo"), session_id=payload.session_id)
    
    # Se ainda n√£o encontrou, tenta com a pergunta original
    if (not contexto or contexto.strip() == "") and query_busca != pergunta:
        contexto = buscar_contexto(pergunta, session_id=payload.session_id)

    # Valida se o contexto achado tem rela√ß√£o com o assunto; se n√£o, descarta para evitar resposta nada a ver
    if contexto and not contexto_relevante(contexto, pergunta, perfil_dict.get("eixo")):
        contexto = ""
    
    # Se n√£o houver contexto, retorna mensagem clara
    if not contexto or contexto.strip() == "":
        return {"answer": "N√£o encontrei informa√ß√µes sobre isso nos documentos dispon√≠veis. Pode reformular sua pergunta ou fornecer mais detalhes sobre o que precisa?"}
    
    # Gera links do Google Maps APENAS se houver pedido EXPL√çCITO de localiza√ß√£o
    # N√£o gera links para perguntas gerais como "como tirar cpf"
    pergunta_lower = pergunta.lower()
    contexto_lower = contexto.lower() if contexto else ""
    pergunta_norm = unicodedata.normalize("NFKD", pergunta_lower).encode("ascii", "ignore").decode("ascii")
    
    # Indicadores de pedido EXPL√çCITO de localiza√ß√£o (mais restritivo)
    pedidos_explicitos = [
        "me manda", "manda a", "envie a", "mostra a", "me mostra",
        "localiza√ß√£o", "localizacao", "endere√ßo", "endereco",
        "pr√≥ximo", "proximo", "mais pr√≥ximo", "perto", "mais perto",
        "onde fica", "onde est√°", "qual endere√ßo", "qual o endere√ßo"
    ]
    
    # Verifica se h√° pedido EXPL√çCITO na pergunta ou no contexto
    tem_pedido_explicito = any(termo in pergunta_lower for termo in pedidos_explicitos)
    pedidos_explicitos_norm = [
        unicodedata.normalize("NFKD", termo.lower()).encode("ascii", "ignore").decode("ascii")
        for termo in pedidos_explicitos
    ]
    pedidos_extras_norm = ["localiza", "localiz", "locaz", "loca", "onde fica", "onde esta", "onde ta"]
    if not tem_pedido_explicito:
        tem_pedido_explicito = any(
            termo in pergunta_norm for termo in pedidos_explicitos_norm + pedidos_extras_norm
        )
    
    # S√≥ gera links se houver pedido EXPL√çCITO
    links_maps = []
    if tem_pedido_explicito:
        # Combina pergunta com contexto para melhor detec√ß√£o do √≥rg√£o
        pergunta_com_contexto = pergunta
        if perfil_dict.get("eixo"):
            pergunta_com_contexto = f"{pergunta} {perfil_dict.get('eixo')}"
        if perfil_dict.get("intent"):
            pergunta_com_contexto = f"{pergunta_com_contexto} {perfil_dict.get('intent')}"
        
        links_maps = gerar_links_orgaos(pergunta_com_contexto, perfil_dict.get("localidade"), forcar_geracao=True)
        
        # Se n√£o gerou links mas h√° eixo no perfil, tenta gerar baseado no eixo
        if not links_maps and perfil_dict.get("eixo"):
            eixo = perfil_dict.get("eixo").lower()
            pergunta_artificial = f"{perfil_dict.get('eixo')} {pergunta}"
            links_maps = gerar_links_orgaos(pergunta_artificial, perfil_dict.get("localidade"), forcar_geracao=True)
    
    bloco_links = ""
    if links_maps:
        links_texto = []
        for link_info in links_maps:
            links_texto.append(f"{link_info['nome']}: {link_info['link']}")
        bloco_links = "\n\nLINKS DO GOOGLE MAPS PARA ENCONTRAR OS √ìRG√ÉOS:\n" + "\n".join(links_texto) + "\n"
    
    contexto_final = f"{bloco_perfil}DADOS DOS DOCUMENTOS:\n{contexto}{bloco_links}"
    
    # Obt√©m e formata o hist√≥rico da conversa
    historico_formatado = ""
    if payload.session_id:
        historico = session_store.obter_historico(payload.session_id, max_mensagens=8)
        if historico:
            historico_formatado = formatar_historico_conversa(historico, max_chars=1500)

    # Classe para acumular resposta durante streaming
    class AcumuladorResposta:
        def __init__(self):
            self.texto = ""
        
        def adicionar(self, pedaco: str):
            self.texto += pedaco

    acumulador = AcumuladorResposta()

    def responder_stream():
        for pedaco in stream_resposta(pergunta, contexto_final, historico_formatado):
            acumulador.adicionar(pedaco)
            yield pedaco
        
        # Ap√≥s terminar de gerar a resposta, salva no hist√≥rico
        if payload.session_id and acumulador.texto:
            session_store.adicionar_mensagem(payload.session_id, pergunta, acumulador.texto)

    salvar_sessao()
    return StreamingResponse(responder_stream(), media_type="text/plain")
